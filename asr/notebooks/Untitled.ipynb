{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a3cf5b2-41af-41c3-9f4c-c0b6f55ac710",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 13 23:06:31 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    42W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba53ddd-ad91-4c63-978f-277878a91d3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1b165c-fed9-4038-a6c5-2c92d306c18f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "model = WhisperModel(\"large-v2\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6ba878a-c3eb-4f44-9088-6b78cbc79278",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>ShowName</th>\n",
       "      <th>FullFileLength</th>\n",
       "      <th>SegmentID</th>\n",
       "      <th>SegmentLength</th>\n",
       "      <th>SegmentStart</th>\n",
       "      <th>SegmentEnd</th>\n",
       "      <th>SpeakerAge</th>\n",
       "      <th>SpeakerGender</th>\n",
       "      <th>SpeakerDialect</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Environment</th>\n",
       "      <th>GroundTruthText</th>\n",
       "      <th>ProcessedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_4/6k_v_SBA_688_2.wav</td>\n",
       "      <td>حكايات بابا فرحان - 02 - 18</td>\n",
       "      <td>488.83</td>\n",
       "      <td>6k_v_SBA_688_2-seg_0_430-28_830</td>\n",
       "      <td>28.40</td>\n",
       "      <td>0.43</td>\n",
       "      <td>28.83</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>Noisy -- ضوضاء</td>\n",
       "      <td>#غير_واضح وجربتوا ولا شي قولوا لي على طول عشان...</td>\n",
       "      <td>غيرواضح وجربتوا ولا شي قولوا لي على طول عشان ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>batch_4/6k_v_SBA_688_2.wav</td>\n",
       "      <td>حكايات بابا فرحان - 02 - 18</td>\n",
       "      <td>488.83</td>\n",
       "      <td>6k_v_SBA_688_2-seg_30_880-39_650</td>\n",
       "      <td>8.77</td>\n",
       "      <td>30.88</td>\n",
       "      <td>39.65</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>Noisy -- ضوضاء</td>\n",
       "      <td>لا خلاص خلوا بالكم خلوا بالكم #غير_واضح لحظة #...</td>\n",
       "      <td>لا خلاص خلوا بالكم خلوا بالكم غيرواضح لحظة غير...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batch_4/6k_v_SBA_688_2.wav</td>\n",
       "      <td>حكايات بابا فرحان - 02 - 18</td>\n",
       "      <td>488.83</td>\n",
       "      <td>6k_v_SBA_688_2-seg_53_970-80_140</td>\n",
       "      <td>26.17</td>\n",
       "      <td>53.97</td>\n",
       "      <td>80.14</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>Clean -- نظيف</td>\n",
       "      <td>متأكد إيوه يا عيد طيب خلاص إلا قولي يا عيد أنت...</td>\n",
       "      <td>متاكد ايوه يا عيد طيب خلاص الا قولي يا عيد انت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>batch_4/6k_v_SBA_688_2.wav</td>\n",
       "      <td>حكايات بابا فرحان - 02 - 18</td>\n",
       "      <td>488.83</td>\n",
       "      <td>6k_v_SBA_688_2-seg_82_240-87_410</td>\n",
       "      <td>5.17</td>\n",
       "      <td>82.24</td>\n",
       "      <td>87.41</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>Noisy -- ضوضاء</td>\n",
       "      <td>أم الخير أم الخير فين رايحة رايحة ألعب كورة يا...</td>\n",
       "      <td>ام الخير ام الخير فين رايحة رايحة العب كورة يا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batch_4/6k_v_SBA_688_2.wav</td>\n",
       "      <td>حكايات بابا فرحان - 02 - 18</td>\n",
       "      <td>488.83</td>\n",
       "      <td>6k_v_SBA_688_2-seg_90_460-96_670</td>\n",
       "      <td>6.21</td>\n",
       "      <td>90.46</td>\n",
       "      <td>96.67</td>\n",
       "      <td>Adult -- بالغ</td>\n",
       "      <td>Female</td>\n",
       "      <td>Najdi</td>\n",
       "      <td>Speaker1متحدث</td>\n",
       "      <td>Clean -- نظيف</td>\n",
       "      <td>أيوه يا سمورة مهم عيد وسعيد بيشتغلوا وأنا رايح...</td>\n",
       "      <td>ايوه يا سمورة مهم عيد وسعيد بيشتغلوا وانا رايح...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210078</th>\n",
       "      <td>batch_1/6k_v2ms_SBA_1569_segmented_0.wav</td>\n",
       "      <td>ابتسامات رمضانية - 12</td>\n",
       "      <td>360.03</td>\n",
       "      <td>6k_v2ms_SBA_1569_segmented_0-seg_312_600-319_060</td>\n",
       "      <td>6.46</td>\n",
       "      <td>312.60</td>\n",
       "      <td>319.06</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>Music -- موسيقى</td>\n",
       "      <td>هاهاها بعد الحين لك وين رايح وين تروح تفضل قال...</td>\n",
       "      <td>هاهاها بعد الحين لك وين رايح وين تروح تفضل قال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210079</th>\n",
       "      <td>batch_1/6k_v2ms_SBA_1569_segmented_0.wav</td>\n",
       "      <td>ابتسامات رمضانية - 12</td>\n",
       "      <td>360.03</td>\n",
       "      <td>6k_v2ms_SBA_1569_segmented_0-seg_319_910-324_750</td>\n",
       "      <td>4.84</td>\n",
       "      <td>319.91</td>\n",
       "      <td>324.75</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>Music -- موسيقى</td>\n",
       "      <td>هو العريس هو جاب سيرة العريس هو جاب سيرته اقعد...</td>\n",
       "      <td>هو العريس هو جاب سيرة العريس هو جاب سيرته اقعد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210080</th>\n",
       "      <td>batch_1/6k_v2ms_SBA_1569_segmented_0.wav</td>\n",
       "      <td>ابتسامات رمضانية - 12</td>\n",
       "      <td>360.03</td>\n",
       "      <td>6k_v2ms_SBA_1569_segmented_0-seg_334_530-343_100</td>\n",
       "      <td>8.57</td>\n",
       "      <td>334.53</td>\n",
       "      <td>343.10</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>Music -- موسيقى</td>\n",
       "      <td>على مهلك والله الله يعطيها هاهاها السابق ونحن...</td>\n",
       "      <td>على مهلك والله الله يعطيها هاهاها السابق ونحن ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210081</th>\n",
       "      <td>batch_1/6k_v2ms_SBA_1569_segmented_0.wav</td>\n",
       "      <td>ابتسامات رمضانية - 12</td>\n",
       "      <td>360.03</td>\n",
       "      <td>6k_v2ms_SBA_1569_segmented_0-seg_344_820-352_060</td>\n",
       "      <td>7.24</td>\n",
       "      <td>344.82</td>\n",
       "      <td>352.06</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>More than 1 speaker اكثر من متحدث</td>\n",
       "      <td>Music -- موسيقى</td>\n",
       "      <td>معايا أقول منك المال ومنها العيال يلا الله يست...</td>\n",
       "      <td>معايا اقول منك المال ومنها العيال يلا الله يست...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210082</th>\n",
       "      <td>batch_1/6k_v2ms_SBA_1569_segmented_0.wav</td>\n",
       "      <td>ابتسامات رمضانية - 12</td>\n",
       "      <td>360.03</td>\n",
       "      <td>6k_v2ms_SBA_1569_segmented_0-seg_358_050-360_030</td>\n",
       "      <td>1.98</td>\n",
       "      <td>358.05</td>\n",
       "      <td>360.03</td>\n",
       "      <td>Adult -- بالغ</td>\n",
       "      <td>Male</td>\n",
       "      <td>Najdi</td>\n",
       "      <td>Speaker6متحدث</td>\n",
       "      <td>Music -- موسيقى</td>\n",
       "      <td>اكشفي ياعروسة إنت في بيتك</td>\n",
       "      <td>اكشفي ياعروسة انت في بيتك</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210083 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        FileName                     ShowName  \\\n",
       "0                     batch_4/6k_v_SBA_688_2.wav  حكايات بابا فرحان - 02 - 18   \n",
       "1                     batch_4/6k_v_SBA_688_2.wav  حكايات بابا فرحان - 02 - 18   \n",
       "2                     batch_4/6k_v_SBA_688_2.wav  حكايات بابا فرحان - 02 - 18   \n",
       "3                     batch_4/6k_v_SBA_688_2.wav  حكايات بابا فرحان - 02 - 18   \n",
       "4                     batch_4/6k_v_SBA_688_2.wav  حكايات بابا فرحان - 02 - 18   \n",
       "...                                          ...                          ...   \n",
       "210078  batch_1/6k_v2ms_SBA_1569_segmented_0.wav        ابتسامات رمضانية - 12   \n",
       "210079  batch_1/6k_v2ms_SBA_1569_segmented_0.wav        ابتسامات رمضانية - 12   \n",
       "210080  batch_1/6k_v2ms_SBA_1569_segmented_0.wav        ابتسامات رمضانية - 12   \n",
       "210081  batch_1/6k_v2ms_SBA_1569_segmented_0.wav        ابتسامات رمضانية - 12   \n",
       "210082  batch_1/6k_v2ms_SBA_1569_segmented_0.wav        ابتسامات رمضانية - 12   \n",
       "\n",
       "        FullFileLength                                         SegmentID  \\\n",
       "0               488.83                   6k_v_SBA_688_2-seg_0_430-28_830   \n",
       "1               488.83                  6k_v_SBA_688_2-seg_30_880-39_650   \n",
       "2               488.83                  6k_v_SBA_688_2-seg_53_970-80_140   \n",
       "3               488.83                  6k_v_SBA_688_2-seg_82_240-87_410   \n",
       "4               488.83                  6k_v_SBA_688_2-seg_90_460-96_670   \n",
       "...                ...                                               ...   \n",
       "210078          360.03  6k_v2ms_SBA_1569_segmented_0-seg_312_600-319_060   \n",
       "210079          360.03  6k_v2ms_SBA_1569_segmented_0-seg_319_910-324_750   \n",
       "210080          360.03  6k_v2ms_SBA_1569_segmented_0-seg_334_530-343_100   \n",
       "210081          360.03  6k_v2ms_SBA_1569_segmented_0-seg_344_820-352_060   \n",
       "210082          360.03  6k_v2ms_SBA_1569_segmented_0-seg_358_050-360_030   \n",
       "\n",
       "        SegmentLength  SegmentStart  SegmentEnd  \\\n",
       "0               28.40          0.43       28.83   \n",
       "1                8.77         30.88       39.65   \n",
       "2               26.17         53.97       80.14   \n",
       "3                5.17         82.24       87.41   \n",
       "4                6.21         90.46       96.67   \n",
       "...               ...           ...         ...   \n",
       "210078           6.46        312.60      319.06   \n",
       "210079           4.84        319.91      324.75   \n",
       "210080           8.57        334.53      343.10   \n",
       "210081           7.24        344.82      352.06   \n",
       "210082           1.98        358.05      360.03   \n",
       "\n",
       "                               SpeakerAge                      SpeakerGender  \\\n",
       "0       More than 1 speaker اكثر من متحدث  More than 1 speaker اكثر من متحدث   \n",
       "1       More than 1 speaker اكثر من متحدث  More than 1 speaker اكثر من متحدث   \n",
       "2       More than 1 speaker اكثر من متحدث  More than 1 speaker اكثر من متحدث   \n",
       "3       More than 1 speaker اكثر من متحدث  More than 1 speaker اكثر من متحدث   \n",
       "4                           Adult -- بالغ                             Female   \n",
       "...                                   ...                                ...   \n",
       "210078  More than 1 speaker اكثر من متحدث  More than 1 speaker اكثر من متحدث   \n",
       "210079  More than 1 speaker اكثر من متحدث  More than 1 speaker اكثر من متحدث   \n",
       "210080  More than 1 speaker اكثر من متحدث  More than 1 speaker اكثر من متحدث   \n",
       "210081  More than 1 speaker اكثر من متحدث  More than 1 speaker اكثر من متحدث   \n",
       "210082                      Adult -- بالغ                               Male   \n",
       "\n",
       "                           SpeakerDialect                            Speaker  \\\n",
       "0       More than 1 speaker اكثر من متحدث  More than 1 speaker اكثر من متحدث   \n",
       "1       More than 1 speaker اكثر من متحدث  More than 1 speaker اكثر من متحدث   \n",
       "2       More than 1 speaker اكثر من متحدث  More than 1 speaker اكثر من متحدث   \n",
       "3       More than 1 speaker اكثر من متحدث  More than 1 speaker اكثر من متحدث   \n",
       "4                                   Najdi                      Speaker1متحدث   \n",
       "...                                   ...                                ...   \n",
       "210078  More than 1 speaker اكثر من متحدث  More than 1 speaker اكثر من متحدث   \n",
       "210079  More than 1 speaker اكثر من متحدث  More than 1 speaker اكثر من متحدث   \n",
       "210080  More than 1 speaker اكثر من متحدث  More than 1 speaker اكثر من متحدث   \n",
       "210081  More than 1 speaker اكثر من متحدث  More than 1 speaker اكثر من متحدث   \n",
       "210082                              Najdi                      Speaker6متحدث   \n",
       "\n",
       "            Environment                                    GroundTruthText  \\\n",
       "0        Noisy -- ضوضاء  #غير_واضح وجربتوا ولا شي قولوا لي على طول عشان...   \n",
       "1        Noisy -- ضوضاء  لا خلاص خلوا بالكم خلوا بالكم #غير_واضح لحظة #...   \n",
       "2         Clean -- نظيف  متأكد إيوه يا عيد طيب خلاص إلا قولي يا عيد أنت...   \n",
       "3        Noisy -- ضوضاء  أم الخير أم الخير فين رايحة رايحة ألعب كورة يا...   \n",
       "4         Clean -- نظيف  أيوه يا سمورة مهم عيد وسعيد بيشتغلوا وأنا رايح...   \n",
       "...                 ...                                                ...   \n",
       "210078  Music -- موسيقى  هاهاها بعد الحين لك وين رايح وين تروح تفضل قال...   \n",
       "210079  Music -- موسيقى  هو العريس هو جاب سيرة العريس هو جاب سيرته اقعد...   \n",
       "210080  Music -- موسيقى   على مهلك والله الله يعطيها هاهاها السابق ونحن...   \n",
       "210081  Music -- موسيقى  معايا أقول منك المال ومنها العيال يلا الله يست...   \n",
       "210082  Music -- موسيقى                          اكشفي ياعروسة إنت في بيتك   \n",
       "\n",
       "                                            ProcessedText  \n",
       "0       غيرواضح وجربتوا ولا شي قولوا لي على طول عشان ا...  \n",
       "1       لا خلاص خلوا بالكم خلوا بالكم غيرواضح لحظة غير...  \n",
       "2       متاكد ايوه يا عيد طيب خلاص الا قولي يا عيد انت...  \n",
       "3       ام الخير ام الخير فين رايحة رايحة العب كورة يا...  \n",
       "4       ايوه يا سمورة مهم عيد وسعيد بيشتغلوا وانا رايح...  \n",
       "...                                                   ...  \n",
       "210078  هاهاها بعد الحين لك وين رايح وين تروح تفضل قال...  \n",
       "210079  هو العريس هو جاب سيرة العريس هو جاب سيرته اقعد...  \n",
       "210080  على مهلك والله الله يعطيها هاهاها السابق ونحن ...  \n",
       "210081  معايا اقول منك المال ومنها العيال يلا الله يست...  \n",
       "210082                          اكشفي ياعروسة انت في بيتك  \n",
       "\n",
       "[210083 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['More than 1 speaker اكثر من متحدث', 'Speaker1متحدث',\n",
       "       'Unclear غير واضح', 'Music موسيقى', 'Speaker2متحدث',\n",
       "       'Speaker3متحدث', 'Speaker4متحدث', 'Speaker5متحدث', 'Speaker6متحدث',\n",
       "       'Other Speakers متحدثين آخرين', 'Laughter ضحك', 'Unknown',\n",
       "       'Ad إعلان'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "\n",
    "root = \"/ibex/user/sulaisw/sada/\"\n",
    "df = pd.read_csv(root + \"train.csv\")\n",
    "#display(df.Speaker.unique())\n",
    "display(df)\n",
    "df.Speaker.unique()\n",
    "#df[\"audio\"] = root + df[\"FileName\"]\n",
    "#ds = datasets.Dataset.from_pandas(df).cast_column(\"audio\", datasets.Audio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0623a82-186e-43b1-bb84-bd56c787a618",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['FileName', 'ShowName', 'FullFileLength', 'SegmentID', 'SegmentLength', 'SegmentStart', 'SegmentEnd', 'SpeakerAge', 'SpeakerGender', 'SpeakerDialect', 'Speaker', 'Environment', 'GroundTruthText', 'ProcessedText'],\n",
       "        num_rows: 210083\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['FileName', 'ShowName', 'FullFileLength', 'SegmentID', 'SegmentLength', 'SegmentStart', 'SegmentEnd', 'SpeakerAge', 'SpeakerGender', 'SpeakerDialect', 'Speaker', 'Environment', 'GroundTruthText', 'ProcessedText'],\n",
       "        num_rows: 21460\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['FileName', 'ShowName', 'FullFileLength', 'SegmentID', 'SegmentLength', 'SegmentStart', 'SegmentEnd', 'SpeakerAge', 'SpeakerGender', 'SpeakerDialect', 'Speaker', 'Environment', 'GroundTruthText', 'ProcessedText'],\n",
       "        num_rows: 21623\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "root = \"/ibex/user/sulaisw/sada/\"\n",
    "ds1 = datasets.load_dataset(root, data_dir=\".\", streaming=False)\n",
    "ds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d37c3bb3-19b0-4780-814d-d5e543acd66b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_audio(row):\n",
    "    row[\"FileName\"] = (root + row[\"FileName\"])\n",
    "    return row\n",
    "\n",
    "\n",
    "def crop_audio(batch):\n",
    "    sr = batch[\"audio\"][\"sampling_rate\"]\n",
    "    start = int(batch[\"SegmentStart\"] * sr)\n",
    "    end = int(batch[\"SegmentEnd\"] * sr)\n",
    "    batch[\"audio\"][\"array\"] = batch[\"audio\"][\"array\"][start:end]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24353cc6-7de2-4eb6-8f47-a3aaf164ef73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds12 \u001b[38;5;241m=\u001b[39m \u001b[43mds1\u001b[49m\u001b[38;5;241m.\u001b[39mmap(load_audio)\u001b[38;5;241m.\u001b[39mrename_column(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFileName\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(ds1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mnext\u001b[39m(it))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds1' is not defined"
     ]
    }
   ],
   "source": [
    "ds12 = ds1.map(load_audio).rename_column(\"FileName\", \"audio\")\n",
    "it = iter(ds1[\"train\"])\n",
    "print(next(it))\n",
    "info_features = datasets.Features({ \"audio\": datasets.Value(dtype='string'),\n",
    "                                                \"FileName\": datasets.Value(dtype='string'),\n",
    "                                                 \"ShowName\": datasets.Value(dtype='string'),\n",
    "                                                 \"FullFileLength\": datasets.Value(dtype='float32'),\n",
    "                                                 \"SegmentID\": datasets.Value(dtype='string'),\n",
    "                                                 \"SegmentLength\": datasets.Value(dtype='float32'),\n",
    "                                                 \"SegmentStart\": datasets.Value(dtype='float32'),\n",
    "                                                 \"SegmentEnd\": datasets.Value(dtype='float32'),\n",
    "                                                 \"SpeakerAge\": datasets.Value(dtype='string'),\n",
    "                                                 \"SpeakerGender\": datasets.Value(dtype='string'),\n",
    "                                                 \"SpeakerDialect\": datasets.Value(dtype='string'),\n",
    "                                                 \"Speaker\": datasets.Value(dtype='string'),\n",
    "                                                 \"Environment\": datasets.Value(dtype='string'),\n",
    "                                                 \"GroundTruthText\": datasets.Value(dtype='string'),\n",
    "                                                 \"ProcessedText\": datasets.Value(dtype='string'),\n",
    "                                                })\n",
    "#ds12[\"train\"].info.features = info_features\n",
    "#ds12[\"validation\"].info.features = info_features\n",
    "#ds12[\"test\"].info.features = info_features\n",
    "print(ds12[\"train\"].info)\n",
    "ds13 = ds12.cast_column(\"audio\", datasets.Audio()).map(crop_audio, writer_batch_size=10)\n",
    "it = iter(ds13[\"train\"])\n",
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc3939ff-4603-42e2-a82e-2d35fd354d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'IterableDatasetDict' object has no attribute 'save_to_disk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mds12\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_to_disk\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msada_ar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'IterableDatasetDict' object has no attribute 'save_to_disk'"
     ]
    }
   ],
   "source": [
    "ds13.save_to_disk(\"sada_ar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b2cfe-a6a1-4063-b687-ea08914b3dc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds1 = ds.map(crop_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b69c94b-5880-415f-b8b3-01a6279c8cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_row = crop_audio(ds[0])\n",
    "input_audio = input_row[\"audio\"][\"array\"]\n",
    "\n",
    "import IPython.display as ipd\n",
    "ref = input_row[\"ProcessedText\"]\n",
    "print(input_row[\"ProcessedText\"])\n",
    "ipd.Audio(input_row[\"audio\"][\"array\"], rate=input_row[\"audio\"][\"sampling_rate\"]) # load a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0eef8-be5d-4a1d-aa43-5a77ea1699b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segments, info = model.transcribe(input_audio)\n",
    "\n",
    "pred = \"\".join(map(lambda x: x.text, segments)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce9491d-b532-4b62-bf22-389d7d21ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "wer = load(\"wer\")\n",
    "cer = load(\"cer\")\n",
    "\n",
    "print(ref, pred)\n",
    "\n",
    "print(\"WER:\", 100 * wer.compute(references=ref, predictions=pred))\n",
    "print(\"CER:\", 100 * cer.compute(references=ref, predictions=pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0637477b-6f35-458a-bc9a-f09692efdb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "root = \"/ibex/user/sulaisw/\"\n",
    "ds = datasets.load_from_disk(root + \"sada_hugging\")\n",
    "# Ignore multi-speaker for now\n",
    "ds = ds.filter(lambda x: x != \"More than 1 speaker اكثر من متحدث\", input_columns=\"Speaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc1348fd-ab14-4a1c-ae28-7ccfe3bf1eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\n",
    "    \"openai/whisper-large\", language=\"arabic\", task=\"transcribe\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c307c47-7501-4c74-bc96-13df60ef12ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(example):\n",
    "    audio = example[\"audio\"]\n",
    "\n",
    "    example = processor(\n",
    "        audio=audio[\"array\"],\n",
    "        sampling_rate=audio[\"sampling_rate\"],\n",
    "        text=example[\"labels\"],\n",
    "    )\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0e48960-8a49-4c3b-ad20-32fd814469d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['audio', 'ShowName', 'FullFileLength', 'SegmentID', 'SegmentLength', 'SegmentStart', 'SegmentEnd', 'SpeakerAge', 'SpeakerGender', 'SpeakerDialect', 'Speaker', 'Environment', 'GroundTruthText', 'ProcessedText'],\n",
      "    num_rows: 157582\n",
      "})\n",
      "Dataset({\n",
      "    features: ['audio', 'ShowName', 'FullFileLength', 'SegmentID', 'SegmentLength', 'SegmentStart', 'SegmentEnd', 'SpeakerAge', 'SpeakerGender', 'SpeakerDialect', 'Speaker', 'Environment', 'GroundTruthText', 'ProcessedText'],\n",
      "    num_rows: 21460\n",
      "})\n",
      "Dataset({\n",
      "    features: ['audio', 'ShowName', 'FullFileLength', 'SegmentID', 'SegmentLength', 'SegmentStart', 'SegmentEnd', 'SpeakerAge', 'SpeakerGender', 'SpeakerDialect', 'Speaker', 'Environment', 'GroundTruthText', 'ProcessedText'],\n",
      "    num_rows: 21623\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds[\"train\"])\n",
    "print(ds[\"validation\"])\n",
    "print(ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63d42b-d1d8-450f-ab80-4a0ea58430fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'ShowName', 'FullFileLength', 'SegmentID', 'SegmentLength', 'SegmentStart', 'SegmentEnd', 'SpeakerAge', 'SpeakerGender', 'SpeakerDialect', 'Speaker', 'Environment', 'GroundTruthText', 'labels'],\n",
      "        num_rows: 156390\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['audio', 'ShowName', 'FullFileLength', 'SegmentID', 'SegmentLength', 'SegmentStart', 'SegmentEnd', 'SpeakerAge', 'SpeakerGender', 'SpeakerDialect', 'Speaker', 'Environment', 'GroundTruthText', 'labels'],\n",
      "        num_rows: 21311\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'ShowName', 'FullFileLength', 'SegmentID', 'SegmentLength', 'SegmentStart', 'SegmentEnd', 'SpeakerAge', 'SpeakerGender', 'SpeakerDialect', 'Speaker', 'Environment', 'GroundTruthText', 'labels'],\n",
      "        num_rows: 21466\n",
      "    })\n",
      "})\n",
      "DatasetInfo(description='', citation='', homepage='', license='', features={'audio': Audio(sampling_rate=None, mono=True, decode=True, id=None), 'ShowName': Value(dtype='string', id=None), 'FullFileLength': Value(dtype='float64', id=None), 'SegmentID': Value(dtype='string', id=None), 'SegmentLength': Value(dtype='float64', id=None), 'SegmentStart': Value(dtype='float64', id=None), 'SegmentEnd': Value(dtype='float64', id=None), 'SpeakerAge': Value(dtype='string', id=None), 'SpeakerGender': Value(dtype='string', id=None), 'SpeakerDialect': Value(dtype='string', id=None), 'Speaker': Value(dtype='string', id=None), 'Environment': Value(dtype='string', id=None), 'GroundTruthText': Value(dtype='string', id=None), 'labels': Value(dtype='string', id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name='csv', dataset_name='sada', config_name='default', version=0.0.0, splits={'train': SplitInfo(name='train', num_bytes=110730991, num_examples=210083, shard_lengths=None, dataset_name='sada'), 'validation': SplitInfo(name='validation', num_bytes=8653192, num_examples=21460, shard_lengths=None, dataset_name='sada'), 'test': SplitInfo(name='test', num_bytes=8689009, num_examples=21623, shard_lengths=None, dataset_name='sada')}, download_checksums={'/ibex/user/sulaisw/sada/train.csv': {'num_bytes': 110568434, 'checksum': None}, '/ibex/user/sulaisw/sada/valid.csv': {'num_bytes': 8660681, 'checksum': None}, '/ibex/user/sulaisw/sada/test.csv': {'num_bytes': 8698104, 'checksum': None}}, download_size=127927219, post_processing_size=None, dataset_size=128073192, size_in_bytes=256000411)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95a03a43e6841c2a44e406a3ac559c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/156390 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# HACK: column rename is necessary for map later\n",
    "ds1 = ds.filter(lambda x: x <= 30, input_columns=\"SegmentLength\").rename_column(\"ProcessedText\", \"labels\")\n",
    "print(ds1)\n",
    "print(ds1[\"train\"].info)\n",
    "ds1 = ds1.map(prepare_dataset, num_proc=1, writer_batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdf7b0a-2cbc-4875-a614-e1ce94cb3ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(\n",
    "        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [\n",
    "            {\"input_features\": feature[\"input_features\"][0]} for feature in features\n",
    "        ]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
    "            labels_batch.attention_mask.ne(1), -100\n",
    "        )\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ff68bf-acdd-4453-98cc-2531078c4ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
    "\n",
    "normalizer = BasicTextNormalizer()\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    # compute orthographic wer\n",
    "    wer_ortho = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    # compute normalised WER\n",
    "    pred_str_norm = [normalizer(pred) for pred in pred_str]\n",
    "    label_str_norm = [normalizer(label) for label in label_str]\n",
    "    # filtering step to only evaluate the samples that correspond to non-zero references:\n",
    "    pred_str_norm = [\n",
    "        pred_str_norm[i] for i in range(len(pred_str_norm)) if len(label_str_norm[i]) > 0\n",
    "    ]\n",
    "    label_str_norm = [\n",
    "        label_str_norm[i]\n",
    "        for i in range(len(label_str_norm))\n",
    "        if len(label_str_norm[i]) > 0\n",
    "    ]\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str_norm, references=label_str_norm)\n",
    "\n",
    "    return {\"wer_ortho\": wer_ortho, \"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf0561f-a4b7-4632-97f4-0f737e3c301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c86fe3a-2def-42b1-902f-d9318ce12196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# disable cache during training since it's incompatible with gradient checkpointing\n",
    "model.config.use_cache = False\n",
    "\n",
    "# set language and task for generation and re-enable cache\n",
    "model.generate = partial(\n",
    "    model.generate, language=\"sinhalese\", task=\"transcribe\", use_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce3daf0-10b4-40d9-b106-6c84493152a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-small-dv\",  # name on the HF Hub\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    lr_scheduler_type=\"constant_with_warmup\",\n",
    "    warmup_steps=50,\n",
    "    max_steps=4000,  # increase to 4000 if you have your own GPU or a Colab paid plan\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    fp16_full_eval=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=16,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a436519-f75e-49b2-806a-c7efe6a0fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=ds1[\"train\"],\n",
    "    eval_dataset=ds1[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c629dead-19fe-486f-b7ed-d48dd95337e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
