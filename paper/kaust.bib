@inproceedings{abdul-mageedARBERTMARBERTDeep2021,
  title = {{{ARBERT}} \& {{MARBERT}}: {{Deep Bidirectional Transformers}} for {{Arabic}}},
  shorttitle = {{{ARBERT}} \& {{MARBERT}}},
  booktitle = {Proceedings of the 59th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and the 11th {{International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 1: {{Long Papers}})},
  author = {Abdul-Mageed, Muhammad and Elmadany, AbdelRahim and Nagoudi, El Moatez Billah},
  date = {2021-08},
  pages = {7088--7105},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online}},
  doi = {10.18653/v1/2021.acl-long.551},
  url = {https://aclanthology.org/2021.acl-long.551},
  urldate = {2023-08-06},
  abstract = {Pre-trained language models (LMs) are currently integral to many natural language processing systems. Although multilingual LMs were also introduced to serve many languages, these have limitations such as being costly at inference time and the size and diversity of non-English data involved in their pre-training. We remedy these issues for a collection of diverse Arabic varieties by introducing two powerful deep bidirectional transformer-based models, ARBERT and MARBERT. To evaluate our models, we also introduce ARLUE, a new benchmark for multi-dialectal Arabic language understanding evaluation. ARLUE is built using 42 datasets targeting six different task clusters, allowing us to offer a series of standardized experiments under rich conditions. When fine-tuned on ARLUE, our models collectively achieve new state-of-the-art results across the majority of tasks (37 out of 48 classification tasks, on the 42 datasets). Our best model acquires the highest ARLUE score (77.40) across all six task clusters, outperforming all other models including XLM-R Large ( 3.4x larger size). Our models are publicly available at https://github.com/UBC-NLP/marbert and ARLUE will be released through the same repository.},
  eventtitle = {{{ACL-IJCNLP}} 2021},
  file = {/Users/wael/Documents/references/Zotero/storage/82U4ME6H/Abdul-Mageed et al. - 2021 - ARBERT & MARBERT Deep Bidirectional Transformers .pdf}
}

@inproceedings{albadiAreTheyOur2018,
  title = {Are They {{Our Brothers}}? {{Analysis}} and {{Detection}} of {{Religious Hate Speech}} in the {{Arabic Twittersphere}}},
  shorttitle = {Are They {{Our Brothers}}?},
  booktitle = {2018 {{IEEE}}/{{ACM International Conference}} on {{Advances}} in {{Social Networks Analysis}} and {{Mining}} ({{ASONAM}})},
  author = {Albadi, Nuha and Kurdi, Maram and Mishra, Shivakant},
  date = {2018-08},
  pages = {69--76},
  issn = {2473-991X},
  doi = {10.1109/ASONAM.2018.8508247},
  abstract = {Religious hate speech in the Arabic Twittersphere is a notable problem that requires developing automated tools to detect messages that use inflammatory sectarian language to promote hatred and violence against people on the basis of religious affiliation. Distinguishing hate speech from other profane and vulgar language is quite a challenging task that requires deep linguistic analysis. The richness of the Arabic morphology and the limited available resources for the Arabic language make this task even more challenging. To the best of our knowledge, this paper is the first to address the problem of identifying speech promoting religious hatred in the Arabic Twitter. In this work, we describe how we created the first publicly available Arabic dataset annotated for the task of religious hate speech detection and the first Arabic lexicon consisting of terms commonly found in religious discussions along with scores representing their polarity and strength. We then developed various classification models using lexicon-based, n-gram-based, and deep-learning-based approaches. A detailed comparison of the performance of different models on a completely new unseen dataset is then presented. We find that a simple Recurrent Neural Network (RNN) architecture with Gated Recurrent Units (GRU) and pre-trained word embeddings can adequately detect religious hate speech with 0.84 Area Under the Receiver Operating Characteristic curve (AUROC).},
  eventtitle = {2018 {{IEEE}}/{{ACM International Conference}} on {{Advances}} in {{Social Networks Analysis}} and {{Mining}} ({{ASONAM}})},
  keywords = {Arabic NLP,Computer science,cyberhate,Linguistics,online radicalization,religious hate speech,social media mining,Task analysis,text analytics,Tools,Training,Twitter},
  file = {/Users/wael/Documents/references/Zotero/storage/P5HH9NCT/Albadi et al. - 2018 - Are they Our Brothers Analysis and Detection of R.pdf;/Users/wael/Documents/references/Zotero/storage/M4RUNRKF/8508247.html}
}

@dataset{alowisheqSADASaudiAudio2023,
  title = {{{SADA}}: {{Saudi Audio Dataset}} for {{Arabic}}},
  shorttitle = {{{SADA}}},
  author = {Alowisheq, Areeb and Alrowithi, Abdulmajeed and Tamran, Aljawharah Bin and Ibrahim, Asma and Aloraini, Raghad and Alnajim, Raneem and Alkahtani, Ranya and Almuasaad, Renad and Alrasheed, Sara and Alsubaie, Shaykhah and Alonaizan, Yaser},
  date = {2023-01-18},
  doi = {10.34740/kaggle/ds/2750028},
  url = {https://www.kaggle.com/datasets/sdaiancai/sada2022},
  urldate = {2023-08-06},
  abstract = {The published data exceeds 600 hours of Arabic audio recordings in various local Saudi dialects, sourced from more than 80 TV shows provided by the Saudi Broadcasting Authority. The National Center for Artificial Intelligence in SDAIA transcribed the data and prepared it for training and processing, together with providing gender-balanced 50 hours for development and testing.},
  langid = {english},
  version = {1},
  file = {/Users/wael/Documents/references/Zotero/storage/FICFMHWP/sada2022.html}
}

@article{bainWhisperXTimeAccurateSpeech,
  title = {{{WhisperX}}: {{Time-Accurate Speech Transcription}} of {{Long-Form Audio}}},
  author = {Bain, Max and Huh, Jaesung and Han, Tengda and Zisserman, Andrew},
  journaltitle = {Visual Geometry Group, University of Oxford},
  abstract = {Large-scale, weakly-supervised speech recognition models, such as Whisper, have demonstrated impressive results on speech recognition across domains and languages. However, the predicted timestamps corresponding to each utterance are prone to inaccuracies, and word-level timestamps are not available out-of-the-box. Further, their application to long audio via buffered transcription prohibits batched inference due to their sequential nature. To overcome the aforementioned challenges, we present WhisperX, a time-accurate speech recognition system with word-level timestamps utilising voice activity detection and forced phoneme alignment. In doing so, we demonstrate state-of-the-art performance on long-form transcription and word segmentation benchmarks. Additionally, we show that pre-segmenting audio with our proposed VAD Cut \& Merge strategy improves transcription quality and enables a twelvefold transcription speedup via batched inference. The code is available open-source1.},
  langid = {english},
  file = {/Users/wael/Documents/references/Zotero/storage/ZTLE63YL/Bain et al. - Visual Geometry Group, University of Oxford.pdf}
}

@inproceedings{boishakhiMultimodalHateSpeech2021,
  title = {Multi-Modal {{Hate Speech Detection}} Using {{Machine Learning}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  author = {Boishakhi, Fariha Tahosin and Shill, Ponkoj Chandra and Alam, Md Golam Rabiul},
  date = {2021-12-15},
  eprint = {2307.11519},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  pages = {4496--4499},
  doi = {10.1109/BigData52589.2021.9671955},
  url = {http://arxiv.org/abs/2307.11519},
  urldate = {2023-07-28},
  abstract = {With the continuous growth of internet users and media content, it is very hard to track down hateful speech in audio and video. Converting video or audio into text does not detect hate speech accurately as human sometimes uses hateful words as humorous or pleasant in sense and also uses different voice tones or show different action in the video. The state-ofthe-art hate speech detection models were mostly developed on a single modality. In this research, a combined approach of multimodal system has been proposed to detect hate speech from video contents by extracting feature images, feature values extracted from the audio, text and used machine learning and Natural language processing.},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/wael/Documents/references/Zotero/storage/MZP98J7W/Boishakhi et al. - 2021 - Multi-modal Hate Speech Detection using Machine Le.pdf}
}

@online{cosentinoLibriMixOpenSourceDataset2020,
  title = {{{LibriMix}}: {{An Open-Source Dataset}} for {{Generalizable Speech Separation}}},
  shorttitle = {{{LibriMix}}},
  author = {Cosentino, Joris and Pariente, Manuel and Cornell, Samuele and Deleforge, Antoine and Vincent, Emmanuel},
  date = {2020-05-22},
  eprint = {2005.11262},
  eprinttype = {arxiv},
  eprintclass = {eess},
  url = {http://arxiv.org/abs/2005.11262},
  urldate = {2023-08-21},
  abstract = {In recent years, wsj0-2mix has become the reference dataset for single-channel speech separation. Most deep learning-based speech separation models today are benchmarked on it. However, recent studies have shown important performance drops when models trained on wsj0-2mix are evaluated on other, similar datasets. To address this generalization issue, we created LibriMix, an open-source alternative to wsj0-2mix, and to its noisy extension, WHAM!. Based on LibriSpeech, LibriMix consists of two- or three-speaker mixtures combined with ambient noise samples from WHAM!. Using Conv-TasNet, we achieve competitive performance on all LibriMix versions. In order to fairly evaluate across datasets, we introduce a third test set based on VCTK for speech and WHAM! for noise. Our experiments show that the generalization error is smaller for models trained with LibriMix than with WHAM!, in both clean and noisy conditions. Aiming towards evaluation in more realistic, conversation-like scenarios, we also release a sparsely overlapping version of LibriMix’s test set.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/wael/Documents/references/Zotero/storage/JGUIYC4L/Cosentino et al. - 2020 - LibriMix An Open-Source Dataset for Generalizable.pdf}
}

@online{gehmanRealToxicityPromptsEvaluatingNeural2020,
  title = {{{RealToxicityPrompts}}: {{Evaluating Neural Toxic Degeneration}} in {{Language Models}}},
  shorttitle = {{{RealToxicityPrompts}}},
  author = {Gehman, Samuel and Gururangan, Suchin and Sap, Maarten and Choi, Yejin and Smith, Noah A.},
  date = {2020-09-25},
  eprint = {2009.11462},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2009.11462},
  url = {http://arxiv.org/abs/2009.11462},
  urldate = {2023-08-09},
  abstract = {Pretrained neural language models (LMs) are prone to generating racist, sexist, or otherwise toxic language which hinders their safe deployment. We investigate the extent to which pretrained LMs can be prompted to generate toxic language, and the effectiveness of controllable text generation algorithms at preventing such toxic degeneration. We create and release RealToxicityPrompts, a dataset of 100K naturally occurring, sentence-level prompts derived from a large corpus of English web text, paired with toxicity scores from a widely-used toxicity classifier. Using RealToxicityPrompts, we find that pretrained LMs can degenerate into toxic text even from seemingly innocuous prompts. We empirically assess several controllable generation methods, and find that while data- or compute-intensive methods (e.g., adaptive pretraining on non-toxic data) are more effective at steering away from toxicity than simpler solutions (e.g., banning "bad" words), no current method is failsafe against neural toxic degeneration. To pinpoint the potential cause of such persistent toxic degeneration, we analyze two web text corpora used to pretrain several LMs (including GPT-2; Radford et. al, 2019), and find a significant amount of offensive, factually unreliable, and otherwise toxic content. Our work provides a test bed for evaluating toxic generations by LMs and stresses the need for better data selection processes for pretraining.},
  pubstate = {preprint},
  version = {2},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/wael/Documents/references/Zotero/storage/AUNNKAGN/Gehman et al. - 2020 - RealToxicityPrompts Evaluating Neural Toxic Degen.pdf;/Users/wael/Documents/references/Zotero/storage/BTZQWUVM/2009.html}
}

@online{gravesGeneratingSequencesRecurrent2014,
  title = {Generating {{Sequences With Recurrent Neural Networks}}},
  author = {Graves, Alex},
  date = {2014-06-05},
  eprint = {1308.0850},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1308.0850},
  urldate = {2023-07-05},
  abstract = {This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Neural and Evolutionary Computing},
  file = {/Users/wael/Documents/references/Zotero/storage/9A9GMJTH/Graves - 2014 - Generating Sequences With Recurrent Neural Network.pdf}
}

@online{hartvigsenToxiGenLargeScaleMachineGenerated2022,
  title = {{{ToxiGen}}: {{A Large-Scale Machine-Generated Dataset}} for {{Adversarial}} and {{Implicit Hate Speech Detection}}},
  shorttitle = {{{ToxiGen}}},
  author = {Hartvigsen, Thomas and Gabriel, Saadia and Palangi, Hamid and Sap, Maarten and Ray, Dipankar and Kamar, Ece},
  date = {2022-07-14},
  eprint = {2203.09509},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2203.09509},
  urldate = {2023-08-06},
  abstract = {Toxic language detection systems often falsely flag text that contains minority group mentions as toxic, as those groups are often the targets of online hate. Such over-reliance on spurious correlations also causes systems to struggle with detecting implicitly toxic language. To help mitigate these issues, we create TOXIGEN, a new large-scale and machinegenerated dataset of 274k toxic and benign statements about 13 minority groups. We develop a demonstration-based prompting framework and an adversarial classifier-in-the-loop decoding method to generate subtly toxic and benign text with a massive pretrained language model (Brown et al., 2020). Controlling machine generation in this way allows TOXIGEN to cover implicitly toxic text at a larger scale, and about more demographic groups, than previous resources of human-written text. We conduct a human evaluation on a challenging subset of TOXIGEN and find that annotators struggle to distinguish machine-generated text from human-written language. We also find that 94.5\% of toxic examples are labeled as hate speech by human annotators. Using three publicly-available datasets, we show that finetuning a toxicity classifier on our data improves its performance on human-written data substantially. We also demonstrate that TOXIGEN can be used to fight machine-generated toxicity as finetuning improves the classifier significantly on our evaluation subset. Our code and data can be found at https:// github.com/microsoft/ToxiGen.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/wael/Documents/references/Zotero/storage/USQA7K6N/Hartvigsen et al. - 2022 - ToxiGen A Large-Scale Machine-Generated Dataset f.pdf}
}

@online{heeDecodingUnderlyingMeaning2023,
  title = {Decoding the {{Underlying Meaning}} of {{Multimodal Hateful Memes}}},
  author = {Hee, Ming Shan and Chong, Wen-Haw and Lee, Roy Ka-Wei},
  date = {2023-06-19},
  eprint = {2305.17678},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.17678},
  url = {http://arxiv.org/abs/2305.17678},
  urldate = {2023-08-14},
  abstract = {Recent studies have proposed models that yielded promising performance for the hateful meme classification task. Nevertheless, these proposed models do not generate interpretable explanations that uncover the underlying meaning and support the classification output. A major reason for the lack of explainable hateful meme methods is the absence of a hateful meme dataset that contains ground truth explanations for benchmarking or training. Intuitively, having such explanations can educate and assist content moderators in interpreting and removing flagged hateful memes. This paper address this research gap by introducing Hateful meme with Reasons Dataset (HatReD), which is a new multimodal hateful meme dataset annotated with the underlying hateful contextual reasons. We also define a new conditional generation task that aims to automatically generate underlying reasons to explain hateful memes and establish the baseline performance of state-of-the-art pre-trained language models on this task. We further demonstrate the usefulness of HatReD by analyzing the challenges of the new conditional generation task in explaining memes in seen and unseen domains. The dataset and benchmark models are made available here: https://github.com/Social-AI-Studio/HatRed},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,I.2.10,I.2.7},
  file = {/Users/wael/Documents/references/Zotero/storage/QNH37GZW/Hee et al. - 2023 - Decoding the Underlying Meaning of Multimodal Hate.pdf;/Users/wael/Documents/references/Zotero/storage/W4IFKSK3/2305.html}
}

@article{hegaziPreprocessingArabicText2021,
  title = {Preprocessing {{Arabic}} Text on Social Media},
  author = {Hegazi, Mohamed Osman and Al-Dossari, Yasser and Al-Yahy, Abdullah and Al-Sumari, Abdulaziz and Hilal, Anwer},
  date = {2021-02-01},
  journaltitle = {Heliyon},
  volume = {7},
  number = {2},
  pages = {e06191},
  issn = {2405-8440},
  doi = {10.1016/j.heliyon.2021.e06191},
  url = {https://www.sciencedirect.com/science/article/pii/S2405844021002966},
  urldate = {2023-08-06},
  abstract = {Currently, social media plays an important role in daily life and routine. Millions of people use social media for different purposes. Large amounts of data flow through online networks every second, and these data contain valuable information that can be extracted if the data are properly processed and analyzed. However, most of the processing results are affected by preprocessing difficulties. This paper presents an approach to extract information from social media Arabic text. It provides an integrated solution for the challenges in preprocessing Arabic text on social media in four stages: data collection, cleaning, enrichment, and availability. The preprocessed Arabic text is stored in structured database tables to provide a useful corpus to which, information extraction and data analysis algorithms can be applied. The experiment in this study reveals that the implementation of the proposed approach yields a useful and full-featured dataset and valuable information. The resultant dataset presented the Arabic text in three structured levels with more than 20 features. Additionally, the experiment provides valuable information and processed results such as topic classification and sentiment analysis.},
  langid = {english},
  keywords = {Arabic text,Data analysis,Database,Document and text processing,Information extraction,Information retrieval,Knowledge discovery,Natural language processing,Sentiment analysis},
  file = {/Users/wael/Documents/references/Zotero/storage/JQUGJ6WN/Hegazi et al. - 2021 - Preprocessing Arabic text on social media.pdf;/Users/wael/Documents/references/Zotero/storage/8QIKBQ2C/S2405844021002966.html}
}

@article{khezzarArHateDetectorDetectionHate2023,
  title = {{{arHateDetector}}: Detection of Hate Speech from Standard and Dialectal {{Arabic Tweets}}},
  shorttitle = {{{arHateDetector}}},
  author = {Khezzar, Ramzi and Moursi, Abdelrahman and Al Aghbari, Zaher},
  date = {2023-03-20},
  journaltitle = {Discover Internet of Things},
  volume = {3},
  doi = {10.1007/s43926-023-00030-9},
  abstract = {Hate speech has become a phenomenon on social media platforms, such as Twitter. These websites and apps that were initially designed to facilitate our expression of free speech, are sometimes being used to spread hate towards each other. In the Arab region, Twitter is a very popular social media platform and thus the number of tweets that contain hate speech is increasing rapidly. Many tweets are written either in standard, dialectal Arabic, or mix. Existing work on Arabic hate speech are targeted towards either standard or single dialectal text, but not both. To fight hate speech more efficiently, in this paper, we conducted extensive experiments to investigate Arabic hate speech in tweets. Therefore, we propose a framework, called arHateDetector, that detects hate speech in the Arabic text of tweets. The proposed arHateDetector supports both standard and several dialectal Arabic. A large Arabic hate speech dataset, called arHateDataset, was compiled from several Arabic standard and dialectal tweets. The tweets are preprocessed to remove the unwanted content. We investigated the use of recent machine learning and deep learning models such as AraBERT to detect hate speech. All classification models used in the investigation are trained with the compiled dataset. Our experiments shows that AraBERT outperformed the other models producing the best performance across seven different datasets including the compiled arHateDataset with an accuracy of 93\%. CNN and LinearSVC produced 88\% and 89\% respectively.},
  file = {/Users/wael/Documents/references/Zotero/storage/7VBYT9W8/Khezzar et al. - 2023 - arHateDetector detection of hate speech from stan.pdf}
}

@online{kumbamExploitingExplainabilityDesign2023,
  title = {Exploiting {{Explainability}} to {{Design Adversarial Attacks}} and {{Evaluate Attack Resilience}} in {{Hate-Speech Detection Models}}},
  author = {Kumbam, Pranath Reddy and Syed, Sohaib Uddin and Thamminedi, Prashanth and Harish, Suhas and Perera, Ian and Dorr, Bonnie J.},
  date = {2023-05-29},
  eprint = {2305.18585},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2305.18585},
  urldate = {2023-08-06},
  abstract = {The advent of social media has given rise to numerous ethical challenges, with hate speech among the most significant concerns. Researchers are attempting to tackle this problem by leveraging hate-speech detection and employing language models to automatically moderate content and promote civil discourse. Unfortunately, recent studies have revealed that hate-speech detection systems can be misled by adversarial attacks, raising concerns about their resilience. While previous research has separately addressed the robustness of these models under adversarial attacks and their interpretability, there has been no comprehensive study exploring their intersection. The novelty of our work lies in combining these two critical aspects, leveraging interpretability to identify potential vulnerabilities and enabling the design of targeted adversarial attacks. We present a comprehensive and comparative analysis of adversarial robustness exhibited by various hatespeech detection models. Our study evaluates the resilience of these models against adversarial attacks using explainability techniques. To gain insights into the models’ decisionmaking processes, we employ the Local Interpretable Modelagnostic Explanations (LIME) framework. Based on the explainability results obtained by LIME, we devise and execute targeted attacks on the text by leveraging the TextAttack tool. Our findings enhance the understanding of the vulnerabilities and strengths exhibited by state-of-the-art hate-speech detection models. This work underscores the importance of incorporating explainability in the development and evaluation of such models to enhance their resilience against adversarial attacks. Ultimately, this work paves the way for creating more robust and reliable hate-speech detection systems, fostering safer online environments and promoting ethical discourse on social media platforms.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/wael/Documents/references/Zotero/storage/3QMDGFYH/Kumbam et al. - 2023 - Exploiting Explainability to Design Adversarial At.pdf}
}

@inproceedings{lakimHolisticAssessmentCarbon2022,
  title = {A {{Holistic Assessment}} of the {{Carbon Footprint}} of {{Noor}}, a {{Very Large Arabic Language Model}}},
  booktitle = {Proceedings of {{BigScience Episode}} \#5 -- {{Workshop}} on {{Challenges}} \& {{Perspectives}} in {{Creating Large Language Models}}},
  author = {Lakim, Imad and Almazrouei, Ebtesam and Abualhaol, Ibrahim and Debbah, Merouane and Launay, Julien},
  date = {2022},
  pages = {84--94},
  publisher = {{Association for Computational Linguistics}},
  location = {{virtual+Dublin}},
  doi = {10.18653/v1/2022.bigscience-1.8},
  url = {https://aclanthology.org/2022.bigscience-1.8},
  urldate = {2023-08-21},
  abstract = {As ever larger language models grow more ubiquitous, it is crucial to consider their environmental impact. Characterised by extreme size and resource use, recent generations of models have been criticised for their voracious appetite for compute, and thus significant carbon footprint. Although reporting of carbon impact has grown more common in machine learning papers, this reporting is usually limited to compute resources used strictly for training. In this work, we propose a holistic assessment of the footprint of an extremescale language model, Noor. Noor is an ongoing project aiming to develop the largest multi-task Arabic language models–with up to 13B parameters–leveraging zero-shot generalisation to enable a wide range of downstream tasks via natural language instructions. We assess the total carbon bill of the entire project: starting with data collection and storage costs, including research and development budgets, pretraining costs, future serving estimates, and other exogenous costs necessary for this international cooperation. Notably, we find that inference costs and exogenous factors can have a significant impact on total budget. Finally, we discuss pathways to reduce the carbon footprint of extreme-scale models.},
  eventtitle = {Proceedings of {{BigScience Episode}} \#5 -- {{Workshop}} on {{Challenges}} \& {{Perspectives}} in {{Creating Large Language Models}}},
  langid = {english},
  file = {/Users/wael/Documents/references/Zotero/storage/XI2UIIGR/Lakim et al. - 2022 - A Holistic Assessment of the Carbon Footprint of N.pdf}
}

@article{luoConvTasNetSurpassingIdeal2019,
  title = {Conv-{{TasNet}}: {{Surpassing Ideal Time-Frequency Magnitude Masking}} for {{Speech Separation}}},
  shorttitle = {Conv-{{TasNet}}},
  author = {Luo, Yi and Mesgarani, Nima},
  date = {2019-08},
  journaltitle = {IEEE/ACM Trans. Audio Speech Lang. Process.},
  volume = {27},
  number = {8},
  eprint = {1809.07454},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  pages = {1256--1266},
  issn = {2329-9290, 2329-9304},
  doi = {10.1109/TASLP.2019.2915167},
  url = {http://arxiv.org/abs/1809.07454},
  urldate = {2023-08-14},
  abstract = {Single-channel, speaker-independent speech separation methods have recently seen great progress. However, the accuracy, latency, and computational cost of such methods remain insufficient. The majority of the previous methods have formulated the separation problem through the time-frequency representation of the mixed signal, which has several drawbacks, including the decoupling of the phase and magnitude of the signal, the suboptimality of time-frequency representation for speech separation, and the long latency in calculating the spectrograms. To address these shortcomings, we propose a fully-convolutional time-domain audio separation network (Conv-TasNet), a deep learning framework for end-to-end time-domain speech separation. Conv-TasNet uses a linear encoder to generate a representation of the speech waveform optimized for separating individual speakers. Speaker separation is achieved by applying a set of weighting functions (masks) to the encoder output. The modified encoder representations are then inverted back to the waveforms using a linear decoder. The masks are found using a temporal convolutional network (TCN) consisting of stacked 1-D dilated convolutional blocks, which allows the network to model the long-term dependencies of the speech signal while maintaining a small model size. The proposed Conv-TasNet system significantly outperforms previous time-frequency masking methods in separating two- and three-speaker mixtures. Additionally, Conv-TasNet surpasses several ideal time-frequency magnitude masks in two-speaker speech separation as evaluated by both objective distortion measures and subjective quality assessment by human listeners. Finally, Conv-TasNet has a significantly smaller model size and a shorter minimum latency, making it a suitable solution for both offline and real-time speech separation applications.},
  keywords = {Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/wael/Documents/references/Zotero/storage/D4YL5YH2/Luo and Mesgarani - 2019 - Conv-TasNet Surpassing Ideal Time-Frequency Magni.pdf;/Users/wael/Documents/references/Zotero/storage/L79BVXFJ/1809.html}
}

@online{machacekTurningWhisperRealTime2023,
  title = {Turning {{Whisper}} into {{Real-Time Transcription System}}},
  author = {Macháček, Dominik and Dabre, Raj and Bojar, Ondřej},
  date = {2023-07-27},
  eprint = {2307.14743},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2307.14743},
  urldate = {2023-07-28},
  abstract = {Whisper is one of the recent state-of-the-art multilingual speech recognition and translation models, however, it is not designed for real time transcription. In this paper, we build on top of Whisper and create Whisper-Streaming, an implementation of real-time speech transcription and translation of Whisper-like models. Whisper-Streaming uses local agreement policy with self-adaptive latency to enable streaming transcription. We show that WhisperStreaming achieves high quality and 3.3 seconds latency on unsegmented long-form speech transcription test set, and we demonstrate its robustness and practical usability as a component in live transcription service at a multilingual conference.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/wael/Documents/references/Zotero/storage/SZ7VJZPC/Macháček et al. - 2023 - Turning Whisper into Real-Time Transcription Syste.pdf}
}

@online{maitiEENDSSJointEndtoEnd2022,
  title = {{{EEND-SS}}: {{Joint End-to-End Neural Speaker Diarization}} and {{Speech Separation}} for {{Flexible Number}} of {{Speakers}}},
  shorttitle = {{{EEND-SS}}},
  author = {Maiti, Soumi and Ueda, Yushi and Watanabe, Shinji and Zhang, Chunlei and Yu, Meng and Zhang, Shi-Xiong and Xu, Yong},
  date = {2022-12-15},
  eprint = {2203.17068},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2203.17068},
  url = {http://arxiv.org/abs/2203.17068},
  urldate = {2023-08-17},
  abstract = {In this paper, we present a novel framework that jointly performs three tasks: speaker diarization, speech separation, and speaker counting. Our proposed framework integrates speaker diarization based on end-to-end neural diarization (EEND) models, speaker counting with encoder-decoder based attractors (EDA), and speech separation using Conv-TasNet. In addition, we propose a multiple 1x1 convolutional layer architecture for estimating the separation masks corresponding to a flexible number of speakers and a fusion technique for refining the separated speech signal with obtained speaker diarization information to improve the joint framework. Experiments using the LibriMix dataset show that our proposed method outperforms the single-task baselines in both diarization and separation metrics for fixed and flexible numbers of speakers and improves speaker counting performance for flexible numbers of speakers. All materials will be open-sourced and reproducible in ESPnet toolkit.},
  pubstate = {preprint},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/wael/Documents/references/Zotero/storage/D6MCX3W6/Maiti et al. - 2022 - EEND-SS Joint End-to-End Neural Speaker Diarizati.pdf;/Users/wael/Documents/references/Zotero/storage/JVEUHE5K/2203.html}
}

@online{mengUnifiedModelingMultiTalker2023,
  title = {Unified {{Modeling}} of {{Multi-Talker Overlapped Speech Recognition}} and {{Diarization}} with a {{Sidecar Separator}}},
  author = {Meng, Lingwei and Kang, Jiawen and Cui, Mingyu and Wu, Haibin and Wu, Xixin and Meng, Helen},
  date = {2023-05-25},
  eprint = {2305.16263},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2305.16263},
  urldate = {2023-07-25},
  abstract = {Multi-talker overlapped speech poses a significant challenge for speech recognition and diarization. Recent research indicated that these two tasks are inter-dependent and complementary, motivating us to explore a unified modeling method to address them in the context of overlapped speech.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/wael/Documents/references/Zotero/storage/GTXRVV77/Meng et al. - 2023 - Unified Modeling of Multi-Talker Overlapped Speech.pdf}
}

@online{morrisTextAttackFrameworkAdversarial2020,
  title = {{{TextAttack}}: {{A Framework}} for {{Adversarial Attacks}}, {{Data Augmentation}}, and {{Adversarial Training}} in {{NLP}}},
  shorttitle = {{{TextAttack}}},
  author = {Morris, John X. and Lifland, Eli and Yoo, Jin Yong and Grigsby, Jake and Jin, Di and Qi, Yanjun},
  date = {2020-10-04},
  eprint = {2005.05909},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2005.05909},
  url = {http://arxiv.org/abs/2005.05909},
  urldate = {2023-08-20},
  abstract = {While there has been substantial research using adversarial attacks to analyze NLP models, each attack is implemented in its own code repository. It remains challenging to develop NLP attacks and utilize them to improve model performance. This paper introduces TextAttack, a Python framework for adversarial attacks, data augmentation, and adversarial training in NLP. TextAttack builds attacks from four components: a goal function, a set of constraints, a transformation, and a search method. TextAttack's modular design enables researchers to easily construct attacks from combinations of novel and existing components. TextAttack provides implementations of 16 adversarial attacks from the literature and supports a variety of models and datasets, including BERT and other transformers, and all GLUE tasks. TextAttack also includes data augmentation and adversarial training modules for using components of adversarial attacks to improve model accuracy and robustness. TextAttack is democratizing NLP: anyone can try data augmentation and adversarial training on any model or dataset, with just a few lines of code. Code and tutorials are available at https://github.com/QData/TextAttack.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/wael/Documents/references/Zotero/storage/IF78QG5U/Morris et al. - 2020 - TextAttack A Framework for Adversarial Attacks, D.pdf;/Users/wael/Documents/references/Zotero/storage/U2NFMVLL/2005.html}
}

@online{Noor,
  title = {Noor},
  url = {https://noor.tii.ae/},
  urldate = {2023-08-21},
  file = {/Users/wael/Documents/references/Zotero/storage/UBU5Z2M5/noor.tii.ae.html}
}

@online{parienteAsteroidPyTorchbasedAudio2020,
  title = {Asteroid: The {{PyTorch-based}} Audio Source Separation Toolkit for Researchers},
  shorttitle = {Asteroid},
  author = {Pariente, Manuel and Cornell, Samuele and Cosentino, Joris and Sivasankaran, Sunit and Tzinis, Efthymios and Heitkaemper, Jens and Olvera, Michel and Stöter, Fabian-Robert and Hu, Mathieu and Martín-Doñas, Juan M. and Ditter, David and Frank, Ariel and Deleforge, Antoine and Vincent, Emmanuel},
  date = {2020-05-08},
  eprint = {2005.04132},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2005.04132},
  url = {http://arxiv.org/abs/2005.04132},
  urldate = {2023-08-23},
  abstract = {This paper describes Asteroid, the PyTorch-based audio source separation toolkit for researchers. Inspired by the most successful neural source separation systems, it provides all neural building blocks required to build such a system. To improve reproducibility, Kaldi-style recipes on common audio source separation datasets are also provided. This paper describes the software architecture of Asteroid and its most important features. By showing experimental results obtained with Asteroid's recipes, we show that our implementations are at least on par with most results reported in reference papers. The toolkit is publicly available at https://github.com/mpariente/asteroid .},
  pubstate = {preprint},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/wael/Documents/references/Zotero/storage/CQ4B9SYK/Pariente et al. - 2020 - Asteroid the PyTorch-based audio source separatio.pdf;/Users/wael/Documents/references/Zotero/storage/3NWS7TWV/2005.html}
}

@article{pereiraALICEAdversarialTraining,
  title = {{{ALICE}}++ : {{Adversarial Training}} for {{Robust}} and {{Effective Temporal Reasoning}}},
  author = {Pereira, Lis Kanashiro and Cheng, Fei and Asahara, Masayuki and Kobayashi, Ichiro},
  abstract = {We propose an enhanced adversarial training algorithm for fine-tuning transformer-based language models (i.e., RoBERTa) and apply it to the temporal reasoning task. Instead of adding the perturbation only to the embedding layer, our algorithm searches for the best combination of layers to add the adversarial perturbation. We further enhance this algorithm with f -divergences, i.e., the JensenShannon divergence. Moreover, we enrich this model with general commonsense knowledge by leveraging data from the general commonsense knowledge task in a multi-task learning scenario. Our results show that our model can improve performance on both English and Japanese temporal reasoning benchmarks, and establishes new state-of-the-art results.},
  langid = {english},
  file = {/Users/wael/Documents/references/Zotero/storage/7YHQ5C5E/Pereira et al. - ALICE++  Adversarial Training for Robust and Effe.pdf}
}

@online{quUnsafeDiffusionGeneration2023,
  title = {Unsafe {{Diffusion}}: {{On}} the {{Generation}} of {{Unsafe Images}} and {{Hateful Memes From Text-To-Image Models}}},
  shorttitle = {Unsafe {{Diffusion}}},
  author = {Qu, Yiting and Shen, Xinyue and He, Xinlei and Backes, Michael and Zannettou, Savvas and Zhang, Yang},
  date = {2023-05-23},
  eprint = {2305.13873},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.13873},
  url = {http://arxiv.org/abs/2305.13873},
  urldate = {2023-08-14},
  abstract = {State-of-the-art Text-to-Image models like Stable Diffusion and DALLE\$\textbackslash cdot\$2 are revolutionizing how people generate visual content. At the same time, society has serious concerns about how adversaries can exploit such models to generate unsafe images. In this work, we focus on demystifying the generation of unsafe images and hateful memes from Text-to-Image models. We first construct a typology of unsafe images consisting of five categories (sexually explicit, violent, disturbing, hateful, and political). Then, we assess the proportion of unsafe images generated by four advanced Text-to-Image models using four prompt datasets. We find that these models can generate a substantial percentage of unsafe images; across four models and four prompt datasets, 14.56\% of all generated images are unsafe. When comparing the four models, we find different risk levels, with Stable Diffusion being the most prone to generating unsafe content (18.92\% of all generated images are unsafe). Given Stable Diffusion's tendency to generate more unsafe content, we evaluate its potential to generate hateful meme variants if exploited by an adversary to attack a specific individual or community. We employ three image editing methods, DreamBooth, Textual Inversion, and SDEdit, which are supported by Stable Diffusion. Our evaluation result shows that 24\% of the generated images using DreamBooth are hateful meme variants that present the features of the original hateful meme and the target individual/community; these generated images are comparable to hateful meme variants collected from the real world. Overall, our results demonstrate that the danger of large-scale generation of unsafe images is imminent. We discuss several mitigating measures, such as curating training data, regulating prompts, and implementing safety filters, and encourage better safeguard tools to be developed to prevent unsafe generation.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Computers and Society,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  file = {/Users/wael/Documents/references/Zotero/storage/KPEW8HV6/Qu et al. - 2023 - Unsafe Diffusion On the Generation of Unsafe Imag.pdf;/Users/wael/Documents/references/Zotero/storage/V26SYJ6N/2305.html}
}

@online{radfordRobustSpeechRecognition2022,
  title = {Robust {{Speech Recognition}} via {{Large-Scale Weak Supervision}}},
  author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  date = {2022-12-06},
  eprint = {2212.04356},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2212.04356},
  url = {http://arxiv.org/abs/2212.04356},
  urldate = {2023-07-26},
  abstract = {We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet. When scaled to 680,000 hours of multilingual and multitask supervision, the resulting models generalize well to standard benchmarks and are often competitive with prior fully supervised results but in a zero-shot transfer setting without the need for any fine-tuning. When compared to humans, the models approach their accuracy and robustness. We are releasing models and inference code to serve as a foundation for further work on robust speech processing.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/wael/Documents/references/Zotero/storage/8SB3YAWN/Radford et al. - 2022 - Robust Speech Recognition via Large-Scale Weak Sup.pdf;/Users/wael/Documents/references/Zotero/storage/FX63WTRV/2212.html}
}

@online{sabirInterpretabilityTransparencyDrivenDetection2023,
  title = {Interpretability and {{Transparency-Driven Detection}} and {{Transformation}} of {{Textual Adversarial Examples}} ({{IT-DT}})},
  author = {Sabir, Bushra and Babar, M. Ali and Abuadbba, Sharif},
  date = {2023-07-02},
  eprint = {2307.01225},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2307.01225},
  url = {http://arxiv.org/abs/2307.01225},
  urldate = {2023-08-14},
  abstract = {Transformer-based text classifiers like BERT, Roberta, T5, and GPT-3 have shown impressive performance in NLP. However, their vulnerability to adversarial examples poses a security risk. Existing defense methods lack interpretability, making it hard to understand adversarial classifications and identify model vulnerabilities. To address this, we propose the Interpretability and Transparency-Driven Detection and Transformation (IT-DT) framework. It focuses on interpretability and transparency in detecting and transforming textual adversarial examples. IT-DT utilizes techniques like attention maps, integrated gradients, and model feedback for interpretability during detection. This helps identify salient features and perturbed words contributing to adversarial classifications. In the transformation phase, IT-DT uses pre-trained embeddings and model feedback to generate optimal replacements for perturbed words. By finding suitable substitutions, we aim to convert adversarial examples into non-adversarial counterparts that align with the model's intended behavior while preserving the text's meaning. Transparency is emphasized through human expert involvement. Experts review and provide feedback on detection and transformation results, enhancing decision-making, especially in complex scenarios. The framework generates insights and threat intelligence empowering analysts to identify vulnerabilities and improve model robustness. Comprehensive experiments demonstrate the effectiveness of IT-DT in detecting and transforming adversarial examples. The approach enhances interpretability, provides transparency, and enables accurate identification and successful transformation of adversarial inputs. By combining technical analysis and human expertise, IT-DT significantly improves the resilience and trustworthiness of transformer-based text classifiers against adversarial attacks.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/wael/Documents/references/Zotero/storage/I3RY76MX/Sabir et al. - 2023 - Interpretability and Transparency-Driven Detection.pdf;/Users/wael/Documents/references/Zotero/storage/29WBR3YH/2307.html}
}

@online{shapiroAlexUAICArabicHate2022,
  title = {{{AlexU-AIC}} at {{Arabic Hate Speech}} 2022: {{Contrast}} to {{Classify}}},
  shorttitle = {{{AlexU-AIC}} at {{Arabic Hate Speech}} 2022},
  author = {Shapiro, Ahmad and Khalafallah, Ayman and Torki, Marwan},
  date = {2022-07-18},
  eprint = {2207.08557},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2207.08557},
  urldate = {2023-08-06},
  abstract = {Online presence on social media platforms such as Facebook and Twitter has become a daily habit for internet users. Despite the vast amount of services the platforms offer for their users, users suffer from cyber-bullying, which further leads to mental abuse and may escalate to cause physical harm to individuals or targeted groups. In this paper, we present our submission to the Arabic Hate Speech 2022 Shared Task Workshop (OSACT5 2022) using the associated Arabic Twitter dataset. The shared task consists of 3 sub-tasks, sub-task A focuses on detecting whether the tweet is offensive or not. Then, For offensive Tweets, sub-task B focuses on detecting whether the tweet is hate speech or not. Finally, For hate speech Tweets, sub-task C focuses on detecting the fine-grained type of hate speech among six different classes. Transformer models proved their efficiency in classification tasks, but with the problem of over-fitting when fine-tuned on a small or an imbalanced dataset. We overcome this limitation by investigating multiple training paradigms such as Contrastive learning and Multi-task learning along with Classification fine-tuning and an ensemble of our top 5 performers. Our proposed solution achieved 0.841, 0.817, and 0.476 macro F1-average in sub-tasks A, B, and C respectively.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/wael/Documents/references/Zotero/storage/QFFQMWY3/Shapiro et al. - 2022 - AlexU-AIC at Arabic Hate Speech 2022 Contrast to .pdf}
}

@online{sharmaTemporalConvolutionNetworks2021,
  title = {Temporal {{Convolution Networks}}},
  author = {Sharma, Abhishek},
  date = {2021-12-22T00:00:00-06:00},
  url = {https://numb3r33.github.io/experiments/deeplearning/math/fastai/tsai/sequencemodelling/2021/12/22/temporal-convolutional-networks.html},
  urldate = {2023-07-25},
  abstract = {What is a Temporal Convolution Network? What are its building blocks? A working implementation using fast.ai and tsai},
  langid = {english},
  organization = {{experiments}},
  file = {/Users/wael/Documents/references/Zotero/storage/APSFS3ZC/temporal-convolutional-networks.html}
}

@article{wolfWhyWeShould2017,
  title = {Why {{We Should Have Seen That Coming}}: {{Comments}} on {{Microsoft}}’s {{Tay}} “{{Experiment}},” and {{Wider Implications}}},
  shorttitle = {Why {{We Should Have Seen That Coming}}},
  author = {Wolf, M. J. and Miller, K. W. and Grodzinsky, F. S.},
  date = {2017-01-01},
  journaltitle = {The ORBIT Journal},
  volume = {1},
  number = {2},
  pages = {1--12},
  issn = {2515-8562},
  doi = {10.29297/orbit.v1i2.49},
  url = {https://www.sciencedirect.com/science/article/pii/S2515856220300493},
  urldate = {2023-08-21},
  abstract = {In this paper we examine the case of Tay, the Microsoft AI chatbot that was launched in March, 2016. After less than 24 hours, Microsoft shut down the experiment because the chatbot was generating tweets that were judged to be inappropriate since they included racist, sexist, and anti-Semitic language. We contend that the case of Tay illustrates a problem with the very nature of learning software (LS is a term that describes any software that changes its program in response to its interactions) that interacts directly with the public, and the developer’s role and responsibility associated with it. We make the case that when LS interacts directly with people or indirectly via social media, the developer has additional ethical responsibilities beyond those of standard software. There is an additional burden of care.},
  keywords = {AI,learning software development,responsibility,software profession,technologies of humility},
  file = {/Users/wael/Documents/references/Zotero/storage/KQFSA6BZ/Wolf et al. - 2017 - Why We Should Have Seen That Coming Comments on M.pdf;/Users/wael/Documents/references/Zotero/storage/IF45L5VV/S2515856220300493.html}
}

@online{xiangBuildRobustTextbased2022,
  title = {Build a Robust Text-Based Toxicity Predictor | {{AWS Machine Learning Blog}}},
  author = {Xiang, Yi and Qi, Yanjun},
  date = {2022-12-06T11:37:53-08:00},
  url = {https://aws.amazon.com/blogs/machine-learning/build-a-robust-text-based-toxicity-predictor/},
  urldate = {2023-08-19},
  abstract = {With the growth and popularity of online social platforms, people can stay more connected than ever through tools like instant messaging. However, this raises an additional concern about toxic speech, as well as cyber bullying, verbal harassment, or humiliation. Content moderation is crucial for promoting healthy online discussions and creating healthy online environments. To detect toxic language content, researchers have been developing deep learning-based natural language processing (NLP) approaches. Most recent methods employ transformer-based pre-trained language models and achieve high toxicity detection accuracy.},
  langid = {american},
  organization = {{AWS Machine Learning Blog}},
  file = {/Users/wael/Documents/references/Zotero/storage/4TRFZDNR/build-a-robust-text-based-toxicity-predictor.html}
}

@online{yuanAudioSymbolicEncoding2023,
  title = {From {{Audio}} to {{Symbolic Encoding}}},
  author = {Yuan, Shenli and Kong, Lingjie and Guo, Jiushuang},
  date = {2023-02-26},
  eprint = {2302.13401},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2302.13401},
  urldate = {2023-07-05},
  abstract = {Automatic music transcription (AMT) aims to convert raw audio to symbolic music representation. As a fundamental problem of music information retrieval (MIR), AMT is considered a difficult task even for trained human experts due to overlap of multiple harmonics in the acoustic signal. On the other hand, speech recognition, as one of the most popular tasks in natural language processing, aims to translate human spoken language to texts. Based on the similar nature of AMT and speech recognition (as they both deal with tasks of translating audio signal to symbolic encoding), this paper investigated whether a generic neural network architecture could possibly work on both tasks. In this paper, we introduced our new neural network architecture built on top of the current state-of-the-art Onsets and Frames [1], and compared the performances of its multiple variations on AMT task. We also tested our architecture with the task of speech recognition. For AMT, our models were able to produce better results compared to the model trained using the state-of-art architecture; however, although similar architecture was able to be trained on the speech recognition task, it did not generate very ideal result compared to other task-specific models.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/wael/Documents/references/Zotero/storage/Z95W4NZ7/Yuan et al. - 2023 - From Audio to Symbolic Encoding.pdf}
}

@online{zhaoMossFormerPushingPerformance2023,
  title = {{{MossFormer}}: {{Pushing}} the {{Performance Limit}} of {{Monaural Speech Separation}} Using {{Gated Single-Head Transformer}} with {{Convolution-Augmented Joint Self-Attentions}}},
  shorttitle = {{{MossFormer}}},
  author = {Zhao, Shengkui and Ma, Bin},
  date = {2023-02-23},
  eprint = {2302.11824},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2302.11824},
  url = {http://arxiv.org/abs/2302.11824},
  urldate = {2023-08-23},
  abstract = {Transformer based models have provided significant performance improvements in monaural speech separation. However, there is still a performance gap compared to a recent proposed upper bound. The major limitation of the current dual-path Transformer models is the inefficient modelling of long-range elemental interactions and local feature patterns. In this work, we achieve the upper bound by proposing a gated single-head transformer architecture with convolution-augmented joint self-attentions, named \textbackslash textit\{MossFormer\} (\textbackslash textit\{Mo\}naural \textbackslash textit\{s\}peech \textbackslash textit\{s\}eparation Trans\textbackslash textit\{Former\}). To effectively solve the indirect elemental interactions across chunks in the dual-path architecture, MossFormer employs a joint local and global self-attention architecture that simultaneously performs a full-computation self-attention on local chunks and a linearised low-cost self-attention over the full sequence. The joint attention enables MossFormer model full-sequence elemental interaction directly. In addition, we employ a powerful attentive gating mechanism with simplified single-head self-attentions. Besides the attentive long-range modelling, we also augment MossFormer with convolutions for the position-wise local pattern modelling. As a consequence, MossFormer significantly outperforms the previous models and achieves the state-of-the-art results on WSJ0-2/3mix and WHAM!/WHAMR! benchmarks. Our model achieves the SI-SDRi upper bound of 21.2 dB on WSJ0-3mix and only 0.3 dB below the upper bound of 23.1 dB on WSJ0-2mix.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/wael/Documents/references/Zotero/storage/E94SR8AK/Zhao and Ma - 2023 - MossFormer Pushing the Performance Limit of Monau.pdf}
}

@online{zhuFreeLBEnhancedAdversarial2020,
  title = {{{FreeLB}}: {{Enhanced Adversarial Training}} for {{Natural Language Understanding}}},
  shorttitle = {{{FreeLB}}},
  author = {Zhu, Chen and Cheng, Yu and Gan, Zhe and Sun, Siqi and Goldstein, Tom and Liu, Jingjing},
  date = {2020-04-23},
  eprint = {1909.11764},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1909.11764},
  urldate = {2023-08-09},
  abstract = {Adversarial training, which minimizes the maximal risk for label-preserving input perturbations, has proved to be effective for improving the generalization of language models. In this work, we propose a novel adversarial training algorithm, FreeLB, that promotes higher invariance in the embedding space, by adding adversarial perturbations to word embeddings and minimizing the resultant adversarial risk inside different regions around input samples. To validate the effectiveness of the proposed approach, we apply it to Transformer-based models for natural language understanding and commonsense reasoning tasks. Experiments on the GLUE benchmark show that when applied only to the finetuning stage, it is able to improve the overall test scores of BERT-base model from 78.3 to 79.4, and RoBERTa-large model from 88.5 to 88.8. In addition, the proposed approach achieves state-of-the-art single-model test accuracies of 85.44\textbackslash\% and 67.75\textbackslash\% on ARC-Easy and ARC-Challenge. Experiments on CommonsenseQA benchmark further demonstrate that FreeLB can be generalized and boost the performance of RoBERTa-large model on other tasks as well. Code is available at \textbackslash url\{https://github.com/zhuchen03/FreeLB .\vphantom\}},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/wael/Documents/references/Zotero/storage/8FH2QMJR/Zhu et al. - 2020 - FreeLB Enhanced Adversarial Training for Natural .pdf}
}
